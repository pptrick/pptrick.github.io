{"pageProps":{"pubData":[{"id":"Cartoon3DRecon","img_path":"/resource/publication/Cartoon3DRecon/cartoon3drecon.png","title":"Generating Animatable 3D Cartoon Faces from Single Portraits","author":"Chuanyu Pan, Guowei Yang, Taijiang Mu, Yu-Kun Lai","conference":"Computer Graphics International (CGI) 2023, and Journal Virtual Reality & Intelligent Hardware (VRIH)","date":"2023-03-18","paper":"https://arxiv.org/pdf/2307.01468","content":"This work introduces a novel framework to generate animatable 3D cartoon faces from a single portrait image. We first transfer an input real-world portrait to a stylized cartoon image with a StyleGAN, then we propose a two-stage reconstruction method to recover the 3D cartoon face with detailed texture. Compared with prior arts, qualitative and quantitative results show that our method achieves better accuracy, aesthetics, and similarity criteria. Furthermore, we demonstrate the capability of real-time facial animation of our 3D model."},{"id":"DTTDv1","img_path":"/resource/publication/DTTDv1/dttdv1.png","title":"Digital Twin Tracking Dataset (DTTD): A New RGB+Depth 3D Dataset for Longer-Range Object Tracking Applications","author":"Weiyu Feng*, Seth Z. Zhao*, Chuanyu Pan*, Adam Chang, Yichen Chen, Zekun Wang, Allen Y. Yang","conference":"IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023, the 2nd Workshop Challenge on Vision Datasets Understanding","date":"2023-02-12","paper":"https://arxiv.org/abs/2302.05991","projectPage":"https://github.com/augcog/DTTDv1","content":"In this work, we create a novel RGB-D dataset, called Digital-Twin Tracking Dataset (DTTD), to enable further research of the 3D object tracking problem and extend potential solutions towards longer ranges and mm localization accuracy. To reduce point cloud noise from the input source, we select the latest Microsoft Azure Kinect as the state-of-the-art time-of-flight (ToF) camera. In total, 103 scenes of 10 common off-the-shelf objects with rich textures are recorded, with each frame annotated with a per-pixel semantic segmentation and ground-truth object poses provided by a commercial motion capturing system. Through experiments, we demonstrate that DTTD can help researchers develop future object tracking methods and analyze new challenges. "},{"id":"ObjectPursuit","img_path":"/resource/publication/ObjectPursuit/img.jpg","title":"Object Pursuit: Building a Space of Objects via Discriminative Weight Generation","author":"Chuanyu Pan*, Yanchao Yang*, Kaichun Mo, Yueqi Duan, Leonidas J. Guibas","conference":"The International Conference on Learning Representations (ICLR), 2022","date":"2022-01-24","paper":"https://arxiv.org/pdf/2112.07954.pdf","projectPage":"https://pptrick.github.io/static/object-pursuit/index.html","video":"https://iclr.cc/virtual/2022/poster/6713","content":"We propose a framework to continuously learn object-centric representations for visual learning and understanding. Our method leverages interactions to effectively sample diverse variations of an object and the corresponding training signals while learning the object-centric representations. Throughout learning, objects are streamed one by one in random order with unknown identities, and are associated with latent codes that can synthesize discriminative weights for each object through a convolutional hypernetwork."},{"id":"Robust3DPortraits","img_path":"/resource/publication/Robust3DPortraits/img.jpg","title":"Robust 3D Self-portraits in Seconds","author":"Zhe Li, Tao Yu, Chuanyu Pan, Zerong Zheng, Yebin Liu","conference":"IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020 (Oral presentation)","date":"2020-03-15","projectPage":"http://www.liuyebin.com/portrait/portrait.html","paper":"https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Robust_3D_Self-Portraits_in_Seconds_CVPR_2020_paper.pdf","video":"http://www.liuyebin.com/portrait/assets/portrait.mp4","content":"We propose an efficient method for robust 3D self-portraits using a single RGBD camera. Benefiting from the proposed PIFusion and lightweight bundle adjustment algorithm, our method can generate detailed 3D self-portraits in seconds and shows the ability to handle extremely loose clothes. To achieve highly efficient and robust reconstruction, we contribute PIFusion, which combines learning-based 3D recovery with volumetric non-rigid fusion to generate accurate sparse partial scans of the performer."}]},"__N_SSG":true}