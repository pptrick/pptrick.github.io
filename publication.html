<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/1bd642b15acbf779.css" as="style"/><link rel="stylesheet" href="/_next/static/css/1bd642b15acbf779.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a7473057b47f01cf.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a7473057b47f01cf.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-91d7f78b5b4003c8.js" defer=""></script><script src="/_next/static/chunks/main-a56127814584ab09.js" defer=""></script><script src="/_next/static/chunks/pages/_app-2e466900404ee073.js" defer=""></script><script src="/_next/static/chunks/0c428ae2-0887ba0301840c65.js" defer=""></script><script src="/_next/static/chunks/98-f61a7a5c8efa3b47.js" defer=""></script><script src="/_next/static/chunks/411-5f6604838e98d29b.js" defer=""></script><script src="/_next/static/chunks/pages/publication-116b06810f8fb85a.js" defer=""></script><script src="/_next/static/80w8LKRfC2OrmJBf-pEiE/_buildManifest.js" defer=""></script><script src="/_next/static/80w8LKRfC2OrmJBf-pEiE/_ssgManifest.js" defer=""></script><script src="/_next/static/80w8LKRfC2OrmJBf-pEiE/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><div><nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top"><div class="container-fluid"><span class="navbar-brand"><a class="Nav_navLink__4uUt6" href="/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="m8 3.293 6 6V13.5a1.5 1.5 0 0 1-1.5 1.5h-9A1.5 1.5 0 0 1 2 13.5V9.293l6-6zm5-.793V6l-2-2V2.5a.5.5 0 0 1 .5-.5h1a.5.5 0 0 1 .5.5z"></path><path fill-rule="evenodd" d="M7.293 1.5a1 1 0 0 1 1.414 0l6.647 6.646a.5.5 0 0 1-.708.708L8 2.207 1.354 8.854a.5.5 0 1 1-.708-.708L7.293 1.5z"></path></svg> Home</a></span><button aria-controls="navbarScroll" type="button" aria-label="Toggle navigation" class="navbar-toggler collapsed"><span class="navbar-toggler-icon"></span></button><div class="justify-content-end navbar-collapse collapse" id="navbarScroll"><div class="navbar-nav"><div class="my-2 nav-item"><a class="Nav_navLink__4uUt6" href="/publication"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M9.293 0H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2V4.707A1 1 0 0 0 13.707 4L10 .293A1 1 0 0 0 9.293 0zM9.5 3.5v-2l3 3h-2a1 1 0 0 1-1-1zM4.5 9a.5.5 0 0 1 0-1h7a.5.5 0 0 1 0 1h-7zM4 10.5a.5.5 0 0 1 .5-.5h7a.5.5 0 0 1 0 1h-7a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 1 0-1h4a.5.5 0 0 1 0 1h-4z"></path></svg> Publication</a></div><div class="my-2 nav-item"><a class="Nav_navLink__4uUt6" href="/test"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 1.783C7.015.936 5.587.81 4.287.94c-1.514.153-3.042.672-3.994 1.105A.5.5 0 0 0 0 2.5v11a.5.5 0 0 0 .707.455c.882-.4 2.303-.881 3.68-1.02 1.409-.142 2.59.087 3.223.877a.5.5 0 0 0 .78 0c.633-.79 1.814-1.019 3.222-.877 1.378.139 2.8.62 3.681 1.02A.5.5 0 0 0 16 13.5v-11a.5.5 0 0 0-.293-.455c-.952-.433-2.48-.952-3.994-1.105C10.413.809 8.985.936 8 1.783z"></path></svg> Education</a></div><div class="my-2 nav-item"><a class="Nav_navLink__4uUt6" href="/test"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M2 6a6 6 0 1 1 10.174 4.31c-.203.196-.359.4-.453.619l-.762 1.769A.5.5 0 0 1 10.5 13h-5a.5.5 0 0 1-.46-.302l-.761-1.77a1.964 1.964 0 0 0-.453-.618A5.984 5.984 0 0 1 2 6zm3 8.5a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1l-.224.447a1 1 0 0 1-.894.553H6.618a1 1 0 0 1-.894-.553L5.5 15a.5.5 0 0 1-.5-.5z"></path></svg> Blog</a></div></div></div></div></nav><div class="layout_container__5R52X"><header class="layout_header__H1FPN"><img src="/images/profile.jpg" class="layout_headerHomeImage__jaw_C utils_borderCircle__s2nTm" alt="Chuanyu Pan (潘传宇)"/><h1 class="utils_heading2Xl___9fFP">Chuanyu Pan (潘传宇)</h1></header><main><style data-emotion="css etlyi9">.css-etlyi9{margin:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;border-width:0;border-style:solid;border-color:rgba(0, 0, 0, 0.12);border-bottom-width:thin;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;white-space:nowrap;text-align:center;border:0;}.css-etlyi9::before,.css-etlyi9::after{position:relative;width:100%;border-top:thin solid rgba(0, 0, 0, 0.12);top:50%;content:"";-webkit-transform:translateY(50%);-moz-transform:translateY(50%);-ms-transform:translateY(50%);transform:translateY(50%);}</style><div class="MuiDivider-root MuiDivider-fullWidth MuiDivider-withChildren publication_divider__rXz2n css-etlyi9" role="separator"><style data-emotion="css c1ovea">.css-c1ovea{display:inline-block;padding-left:calc(8px * 1.2);padding-right:calc(8px * 1.2);}</style><span class="MuiDivider-wrapper css-c1ovea"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M9.293 0H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2V4.707A1 1 0 0 0 13.707 4L10 .293A1 1 0 0 0 9.293 0zM9.5 3.5v-2l3 3h-2a1 1 0 0 1-1-1zM4.5 9a.5.5 0 0 1 0-1h7a.5.5 0 0 1 0 1h-7zM4 10.5a.5.5 0 0 1 .5-.5h7a.5.5 0 0 1 0 1h-7a.5.5 0 0 1-.5-.5zm.5 2.5a.5.5 0 0 1 0-1h4a.5.5 0 0 1 0 1h-4z"></path></svg> Publication</span></div><ul class="publication_Container__EEudI"><ul class="publication_pubContainer__LlKyQ"><style data-emotion="css isbt42">.css-isbt42{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-16px;width:calc(100% + 16px);margin-left:-16px;}.css-isbt42>.MuiGrid-item{padding-top:16px;}.css-isbt42>.MuiGrid-item{padding-left:16px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-2 css-isbt42"><style data-emotion="css 4xkoi8">.css-4xkoi8{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}@media (min-width:600px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:900px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1200px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-3 css-4xkoi8"><div class="publication_pubImg__ngHRq"><div data-rmiz-wrap="visible"><img src="\resource\publication\ObjectPursuit\img.jpg" class="publication_pubImg__ngHRq" alt="ObjectPursuit"/><button aria-label="Zoom image" data-rmiz-btn-open="true"></button></div></div></div><style data-emotion="css 14ybvol">.css-14ybvol{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}@media (min-width:600px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:900px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1200px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1536px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-9 css-14ybvol"><div class="publication_pubTitle__iFRsM">Object Pursuit: Building a Space of Objects via Discriminative Weight Generation</div><div class="publication_pubAuthor__2E0_4">Chuanyu Pan*, Yanchao Yang*, Kaichun Mo, Yueqi Duan, Leonidas J. Guibas</div><div class="publication_pubConf__vVTfv">The International Conference on Learning Representations (ICLR), 2022</div><div>2022-01-24</div></div></div></ul><ul class="publication_pubContainer__LlKyQ"><style data-emotion="css isbt42">.css-isbt42{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-16px;width:calc(100% + 16px);margin-left:-16px;}.css-isbt42>.MuiGrid-item{padding-top:16px;}.css-isbt42>.MuiGrid-item{padding-left:16px;}</style><div class="MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-2 css-isbt42"><style data-emotion="css 4xkoi8">.css-4xkoi8{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}@media (min-width:600px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:900px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1200px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-4xkoi8{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-3 css-4xkoi8"><div class="publication_pubImg__ngHRq"><div data-rmiz-wrap="visible"><img src="\resource\publication\Robust3DPortraits\img.jpg" class="publication_pubImg__ngHRq" alt="Robust3DPortraits"/><button aria-label="Zoom image" data-rmiz-btn-open="true"></button></div></div></div><style data-emotion="css 14ybvol">.css-14ybvol{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}@media (min-width:600px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:900px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1200px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1536px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}</style><div class="MuiGrid-root MuiGrid-item MuiGrid-grid-xs-9 css-14ybvol"><div class="publication_pubTitle__iFRsM">Robust 3D Self-portraits in Seconds</div><div class="publication_pubAuthor__2E0_4">Zhe Li, Tao Yu, Chuanyu Pan, Zerong Zheng, Yebin Liu</div><div class="publication_pubConf__vVTfv">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020 (Oral presentation)</div><div>2020-03-15</div></div></div></ul></ul></main></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"pubData":[{"id":"ObjectPursuit","img_path":"\\resource\\publication\\ObjectPursuit\\img.jpg","title":"Object Pursuit: Building a Space of Objects via Discriminative Weight Generation","author":"Chuanyu Pan*, Yanchao Yang*, Kaichun Mo, Yueqi Duan, Leonidas J. Guibas","conference":"The International Conference on Learning Representations (ICLR), 2022","date":"2022-01-24","content":"We propose a framework to continuously learn object-centric representations for visual learning and understanding. Our method leverages interactions to effectively sample diverse variations of an object and the corresponding training signals while learning the object-centric representations. Throughout learning, objects are streamed one by one in random order with unknown identities, and are associated with latent codes that can synthesize discriminative weights for each object through a convolutional hypernetwork."},{"id":"Robust3DPortraits","img_path":"\\resource\\publication\\Robust3DPortraits\\img.jpg","title":"Robust 3D Self-portraits in Seconds","author":"Zhe Li, Tao Yu, Chuanyu Pan, Zerong Zheng, Yebin Liu","conference":"IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020 (Oral presentation)","date":"2020-03-15","content":"In this paper, we propose an efficient method for robust 3D self-portraits using a single RGBD camera. Benefiting from the proposed PIFusion and lightweight bundle adjustment algorithm, our method can generate detailed 3D self-portraits in seconds and shows the ability to handle extremely loose clothes. To achieve highly efficient and robust reconstruction, we contribute PIFusion, which combines learning-based 3D recovery with volumetric non-rigid fusion to generate accurate sparse partial scans of the performer. Moreover, a non-rigid volumetric deformation method is proposed to continuously refine the learned shape prior. Finally, a lightweight bundle adjustment algorithm is proposed to guarantee that all the partial scans can not only ``loop'' with each other, but also keep consistent with the selected live key observations. Results and experiments show that the proposed method achieves more robust and efficient 3D self-portraits compared with state-of-the-art methods."}]},"__N_SSG":true},"page":"/publication","query":{},"buildId":"80w8LKRfC2OrmJBf-pEiE","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>